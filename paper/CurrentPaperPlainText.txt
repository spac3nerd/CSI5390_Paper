Abstract[a] - Distributed interactive multi-body simulations are an increasingly prevalent breed of software and demand unique strategies with respect to testing. Classically non-networked multiplayer video gaming takes place on a single machine hosting a single local environment within which all players directly control actors in a simulation. Modern networked gaming often requires that a singular environment be remotely hosted with all player-controlled actors and their interactions be distributed to connected client applications.[b] With all these simulations, it is paramount that the individual units in the simulations as well as all the moving parts in the server are rigorously tested. The research gathered for this paper will outline the testing methodologies that we find to be the most significant. Combining strong unit and integration testing inside the server, each simulation needs to be tested for usability, compatibility, and reliability. Likewise, since the integrity of the simulation is paramount, susceptibility to malicious or incorrect information fed into the system  must be mitigated, and as such, we will explore mechanisms by which test the system.


I. Introduction
  
  In our work we aim to create a testing framework for an online multiplayer javascript application called NodeTank. This application involves two primary components, a server, and one or more connected clients. Each client instance renders the play environment to the players as well as a tank object and accepts control inputs from a player. Client instances are responsible for forwarding control inputs to the server. The server is responsible for tracking and maintaining state information relevant to the gameplay. Various examples of state include health status, position, and orientation. This information needs to be forwarded from the server to the client applications with minimal latency in order to provide a continuous stream of snapshots of the game’s state. Client applications are also responsible for recreating and displaying this information for the player with the end-goal of providing all players with consistent up-to-date information.
        Unit testing can be achieved through traditional means of subjecting applicable functions to predetermined inputs and comparing their results to expected results. Functional testing presents a less straight-forward solution. In the basic case, there are two clients and one server, three separate processes that are interacting with one another. These interactions can potentially generate a very wide range of outputs and [c][d][e][f][g][h]behaviors of which only a very small subset would be considered correct. Not only do the specific actions and reactions between these processes determine program correctness, but the timing between them determine correctness.


II. Related Works
   The works of Ariurek et al[2] are very interesting to our research because they propose several mechanisms by which to introduce automated test agents into the game development cycle with the goal of finding defects. They have proposed two mechanisms by which to facilitate this automation; human-like agents and synthetic agents.A human-like agent is a separate program which learns the rules and behavior of a game via reinforcement learning. With reinforcement learning, this type of agent would learn how a human would play the game as it would have the same reward incentive as a human player, and is thus likely to detect defects which are similar in nature to those detected by humans. Their proposed synthetic agent is also a type of program which is trained via reinforcement learning, except its goals are not inline with the goals of a real human player. For example, a synthetic agent could be rewarded with implementing a scenario which would be detrimental to winning the game, but which would be likely to reveal a defect otherwise hidden from expected behavior. Using both of these methods, Ariurek et al have created a system in which the quality of a game could be tested automatically and not in a predetermined fashion. 


   Rezin et al[3] developed a model checking mechanism for a specific multiplayer game. They did so by creating a list of attributes which are mapped to parameters into the model - for example, each object must have some position identifier, X/Y/Z as well as a vector which describes the orientation. Our case study, NodeTank, will also suffer from the same problem as their case study in that state explosion due the millions of possible position/orientation combinations and as such the game model must be reduced to meaningfully study it. 


Peusaari et al[5] discuss the computational issues and challenges of distributed human-in-the-loop simulations of a basic architecture consisting of several satellite components focused around a management component. The specific components include a client, server, motion platform controller, I/O controller, and a manager. The manager distributes setup instructions for the simulation as well as collecting and processing data  streams from the other components. The servers play the primary roles of computational units performing physics/dynamics processing. The relationship between these client and server components are analogous to the client-server relationship NodeTank utilizes. The piece that we will need to construct is the manager, a component that will allow for the distributed initialization of tests and the data collection of those tests. However, in our case, this manager will observe and report on the behavior code itself rather than sensor data. Components that don’t translate to our work are, with reason, the motion controller. Several of the challenges of distributed simulation that are relevant in this paper may be relevant to our work as well. Peusaari outlines the following three main challenges to the distributed simulation. The end result of the simulation should be capable of executing in real-time. Secondly, the system, being distributed across a network, will be naturally intolerant of delays. The more delay that is introduced, the more the data and validity of the experiment drift. Thirdly data transmissions should be well-planned and organized in such a way that minimizes hindrance of the simulation and its core goals. Multi-body simulations require that, at a minimum, coordinates and orientations of bodies subject to physics and dynamics calculations be routinely transmitted at reliable intervals.
These are all concerns of NodeTank. While they may be to a lesser degree, as NodeTank is a game rather than a tool for executing experiments for research, they will be valid concerns to the degree of their perceptibility. As delays grow, corresponds to the players’ abilities to enjoy the experience decline.


III. Approach[i][j][k]


   Our approach is to develop a testing framework for NodeTank will combine abstract testing of models, unit testing, and functional testing[l] into a single, yet modular, utility. The effort of functional testing will involve the synchronization of timing of outputs from the server as well as the clients involved. The testing utility should be distributable just as the software being tested and a means of distributing and launching a test should be runnable from a single test location. Any data and any results of a test run should also be collected and delivered to the single test location where it will be analyzed and classified as either a success or failure. Current design will feature the integration of the Labstreaminglayer tool and a Labstreaminglayer server. This tool will allow for the collection of any data or output deemed necessary for a given test. It will allow for record sub-millisecond timing of events from multiple machines over a local area network.
   For the goal of developing and testing the game locally on one machine, we will also be able to leverage the fact that it is built to run in the browser on an interpreted language to run test suites end to end. Firstly, we will investigate an approach similar to Ariyurek et al[2] in order to develop an automated system to test the application as well as to automatically find problems with it. Secondly, the fact that the application in its unobstructed build state will have its internal state visible and inspectable from the outside. That is to say, if we were to run multiple client simulations concurrently, we would be able to inspect the state of the simulation on each one of the said client machines independently. This would allow us to inspect the correctness of the model in real time from the perspective of each client. Likewise, the fact that we could control each client independently, we will be able to gauge the susceptibility of the simulation to erroneous or malicious data by willfully introducing it to one client, and checking if the erroneous data was propagated to the other clients. 




IV. Sources


[1] A. Valadares, “Aspect-oriented architectural style for distributed interactive simulations”, 2016, Available from ProQuest Dissertations & Theses Global. (1881527059). Retrieved from https://search-proquest-com.huaryu.kl.oakland.edu/docview/1881527059?accountid=12924
[2] S. Ariyurek, “Automated Video Game Testing Using
Synthetic and Human-Like Agents”, 2019, Available: https://arxiv.org/pdf/1906.00317.pdf
[3] R. Rezin, ”Model Checking in multiplayer games development”, Innopolis University, 2017, Available: https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8432324
[4] R. Hofer “DIS Today”, 1995, Available:
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=400453
[5] J.Peusaari, “Distributed Issues in Real-Time Interactive Simulations”, Department of Technology Lappeenranta University of Technology, Finland, Available: https://ieeexplore.ieee.org/abstract/document/5361761
[a]I've saved the previous comments at the same level as this paper since they were lost after I changed the format of the paper
[b]I edited the first part of the abstract. It may be worth reviewing/correcting
[c]We can attempt to do some model checking - one of the papers deals with this aspect.
[d]@sfbadila@oakland.edu do you want to add that in? I started reading through those sources this morning, but i have not finished yet.
[e]Yeah, I'm describing it in related works and I'll see if I can make it fir into the intro
[f]@sfbadila@oakland.edu do you see the live chat?
[g]Sorry, I had to step away for some work item - I don't see the live chat unfortunately
[h]No worries. im tending to some other work at the moment. I think we're approaching where we need to be for tonight's class/submission. perhaps some additional cleanup beforehand? but i will be back on later today.
[i]I suggest we focus in on a specific type of distributed system - my take is that a multiplayer game protocol will probably be the best bet in terms of available material and the possibility of us building such as system. The DIS  military application is also promising, but less accessible to us.
[j]yes I agree, I wasn't intending that we target DIS specifically, I just mentioned it because I wasn't sure what else to call it.
Do either of you have feedback on the email I had sent out?
[k]I found a couple of papers that describe DIS', and we can spring board off of that before delving into a specific, but related implementation of such a system
[l]Im going to include some form of what i mentioned in email for now.


This should be changed/updated/adapted as this document ages.